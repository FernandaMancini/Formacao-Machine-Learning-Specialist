{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FDbUuYmFPoFK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as nf\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformações para os dados\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Carregamento dos dados\n",
        "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Carregamento dos dados de validação\n",
        "valset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "uHwedBpqRvIA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "3veuE6p5Ss-r",
        "outputId": "3bf4a6db-438a-4022-fad9-8fe5d6ae9a6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6725901150>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) # Para verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) # Para verificar as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diLGMFY_UJrA",
        "outputId": "e19f0120-e563-48ea-c4e9-94f7a29d1c33"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128) #camada de entrada, 784 neurônios que ligam a 128\n",
        "    self.linear2 = nn.Linear(128, 64) #camada interna 1, 128 neurônios que ligam a 64\n",
        "    self.linear3 = nn.Linear(64, 10) #camada interna 2, 64 neurônios que ligam a 10\n",
        "    # para a camada de saída não é necessario definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self, x):\n",
        "      X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
        "      X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
        "      X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "      return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "YBZsOT_HXele"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) #define a política de atualização dos pesos e da bias\n",
        "  inicio = time() #timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "  criterio = nn.NLLLoss() #definindo o criterio para calcular a perda\n",
        "  EPOCHS = 10 # numero de epochs que o algoritmo rodará\n",
        "  modelo.train() # ativando o modo de treinamento do modelo\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "\n",
        "      imagens = imagens.view(imagens.shape[0], -1) #convertendo as imagens para \"vetores\"\n",
        "      otimizador.zero_grad() # zerando os gradientes por conta do cieclo anterior\n",
        "\n",
        "      output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device)) #calculando a perda da epoch em questão\n",
        "\n",
        "      perda_instantanea.backward() # back propagation a partir da perda\n",
        "\n",
        "      otimizador.step() # atualizado os pesos e a bias\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
        "\n",
        "    else:\n",
        "      print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos) \", (time()-inicio/60))\n"
      ],
      "metadata": {
        "id": "LRNarlUHwq4h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "      #desativr o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device)) # output do modelo em escala logarítmica\n",
        "\n",
        "      ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      etiqueta_pred = probab.index(max(probab)) # converte o tensor em um numero\n",
        "      etiqueta_certa = etiquetas.numpy()[i]\n",
        "      if (etiqueta_certa == etiqueta_pred): #comparaa a previsão com o valor correto\n",
        "        conta_corretas += 1\n",
        "      conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas = \", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\", format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "yzM6YVoO2Jn_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II3AnZgr4vmp",
        "outputId": "bccebb78-11a5-4f5f-dae0-a11522c76fdc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}
